// =====================================================
// ANALISADOR MULTIMODAL DE CRIATIVOS
// =====================================================
// Usa GPT-5.2 Vision para imagens e Whisper + Vision para v√≠deos
// Gera copy altamente contextualizada baseada no conte√∫do real
// =====================================================

import OpenAI from 'openai';
import type { GeneratedCopy } from './types';
// ‚úÖ IMPORTAR fun√ß√µes do video-analyzer que j√° extraem √°udio corretamente
import { 
  extractAudioFromVideo, 
  transcribeAudioWithWhisper, 
  extractFramesFromVideo,
  analyzeFramesWithGPT as analyzeFramesWithGPTFromVideoAnalyzer
} from '@/lib/video-analyzer';
import fs from 'fs/promises';
import path from 'path';
import os from 'os';

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

// =====================================================
// TIPOS
// =====================================================

interface CreativeAnalysisResult {
  imageDescription: string;
  audioTranscription?: string;
  primaryTexts: string[];
  headlines: string[];
  analysisType: 'image' | 'video' | 'video_vision_only';
}

interface AnalyzeCreativeParams {
  mediaUrl: string;
  mediaType: 'image' | 'video';
  objective: string;
  targetAudience: string;
  thumbnailUrl?: string; // Para v√≠deos
  audioBuffer?: Buffer;  // Para transcri√ß√£o Whisper
}

// =====================================================
// TRANSCRI√á√ÉO DE V√çDEO (Whisper via FFmpeg)
// =====================================================

/**
 * Transcreve o √°udio de um v√≠deo usando FFmpeg + Whisper API
 * ‚úÖ CORRIGIDO: Extrai MP3 primeiro, depois envia ao Whisper
 * @param videoBuffer - Buffer do arquivo de v√≠deo
 * @param fileName - Nome do arquivo original
 * @returns Transcri√ß√£o do √°udio ou null se falhar
 */
export async function transcribeVideoAudio(
  videoBuffer: Buffer,
  fileName: string
): Promise<string | null> {
  console.log(`üé§ [transcribeVideoAudio] Processando: ${fileName}`);

  // Criar arquivo tempor√°rio do v√≠deo
  const tempDir = os.tmpdir();
  const videoPath = path.join(tempDir, `video-${Date.now()}.mp4`);
  
  try {
    // 1. Salvar v√≠deo em arquivo tempor√°rio
    await fs.writeFile(videoPath, videoBuffer);
    console.log(`   üìÅ V√≠deo salvo temporariamente: ${videoPath}`);
    
    // 2. Extrair √°udio para MP3 usando FFmpeg
    const audioPath = await extractAudioFromVideo(videoPath);
    
    if (!audioPath) {
      console.log('   ‚ö†Ô∏è Falha ao extrair √°udio (FFmpeg n√£o dispon√≠vel)');
      return null;
    }
    
    // 3. Transcrever MP3 com Whisper
    const transcription = await transcribeAudioWithWhisper(audioPath);
    
    // 4. Limpar arquivos tempor√°rios
    await fs.unlink(videoPath).catch(() => {});
    await fs.unlink(audioPath).catch(() => {});
    
    if (transcription && transcription !== '[Transcri√ß√£o n√£o dispon√≠vel]') {
      console.log(`   ‚úÖ Transcri√ß√£o obtida: ${transcription.substring(0, 100)}...`);
      return transcription;
    }
    
    return null;
  } catch (error) {
    console.error('‚ùå Erro na transcri√ß√£o:', error);
    
    // Limpar arquivo tempor√°rio em caso de erro
    await fs.unlink(videoPath).catch(() => {});
    
    return null;
  }
}

// =====================================================
// AN√ÅLISE VISUAL (GPT-5.2 Vision)
// =====================================================

/**
 * Analisa uma imagem e gera copy contextualizada
 * @param imageUrl - URL p√∫blica da imagem
 * @param objective - Objetivo da campanha
 * @param targetAudience - P√∫blico-alvo
 * @returns Descri√ß√£o da imagem + copies geradas
 */
export async function analyzeImageForCopy(
  imageUrl: string,
  objective: string,
  targetAudience: string
): Promise<CreativeAnalysisResult> {
  console.log(`üëÅÔ∏è Analisando imagem com Vision: ${imageUrl.substring(0, 50)}...`);

  const systemPrompt = `Voc√™ √© um copywriter especialista em an√∫ncios de alta convers√£o para Facebook/Instagram.
Sua miss√£o √© analisar a imagem fornecida e criar textos de an√∫ncio ALTAMENTE CONTEXTUALIZADOS.

IMPORTANTE: Suas copies devem fazer refer√™ncia DIRETA ao que aparece na imagem.
- Se h√° uma pessoa, descreva caracter√≠sticas relevantes
- Se h√° um produto, destaque-o
- Se h√° uma a√ß√£o sendo executada, conecte com o benef√≠cio
- Use elementos visuais para criar ganchos emocionais`;

  const userPrompt = `ANALISE ESTA IMAGEM e crie copy de an√∫ncio contextualizada.

CONTEXTO DA CAMPANHA:
- Objetivo: ${objective}
- P√∫blico-alvo: ${targetAudience}

TAREFA:
1. Descreva brevemente o que voc√™ v√™ na imagem
2. Gere 3 op√ß√µes de Primary Text (80-150 chars) que fa√ßam REFER√äNCIA DIRETA √† imagem
3. Gere 3 op√ß√µes de Headline (20-40 chars) conectando imagem + objetivo

REGRAS:
- Primary Text deve come√ßar com gancho emocional ou problema
- Use emojis estrategicamente (m√°ximo 2 por texto)
- Headlines devem ser diretas e impactantes
- CONECTE o visual ao benef√≠cio do produto/servi√ßo

FORMATO (JSON):
{
  "imageDescription": "descri√ß√£o do que aparece na imagem",
  "primaryTexts": ["texto1...", "texto2...", "texto3..."],
  "headlines": ["headline1", "headline2", "headline3"]
}

Responda APENAS com o JSON.`;

  try {
    const response = await openai.chat.completions.create({
      model: 'gpt-5.2', // Modelo mais recente (Dezembro 2025) - Suporta Vision
      messages: [
        { role: 'system', content: systemPrompt },
        {
          role: 'user',
          content: [
            { type: 'text', text: userPrompt },
            { type: 'image_url', image_url: { url: imageUrl, detail: 'high' } },
          ],
        },
      ],
      temperature: 0.8, // GPT-5.2 se beneficia de mais criatividade
      max_completion_tokens: 800,
    });

    const content = response.choices[0]?.message?.content;
    if (!content) throw new Error('Sem resposta da OpenAI');

    const cleanContent = content.replace(/```json\n?|\n?```/g, '').trim();
    const parsed = JSON.parse(cleanContent);

    console.log('‚úÖ An√°lise de imagem conclu√≠da:', parsed.imageDescription);

    return {
      imageDescription: parsed.imageDescription,
      primaryTexts: parsed.primaryTexts,
      headlines: parsed.headlines,
      analysisType: 'image',
    };
  } catch (error) {
    console.error('‚ùå Erro na an√°lise de imagem:', error);
    
    // Fallback: copy gen√©rica
    return {
      imageDescription: 'Imagem n√£o analisada',
      primaryTexts: [
        `üéØ Descubra como ${objective.toLowerCase()} pode transformar sua carreira. Resultados comprovados!`,
        `‚ö° A solu√ß√£o que ${targetAudience.toLowerCase()} esperavam para ${objective.toLowerCase()}. N√£o perca!`,
        `üí° Milhares de ${targetAudience.toLowerCase()} j√° transformaram suas vidas. E voc√™?`,
      ],
      headlines: [
        `${objective.split(' ')[0]} para ${targetAudience}`,
        'Transforme sua Carreira',
        'Resultados Comprovados',
      ],
      analysisType: 'image',
    };
  }
}

// =====================================================
// AN√ÅLISE DE V√çDEO (FFmpeg + Whisper + Vision)
// =====================================================

/**
 * Analisa um v√≠deo usando FFmpeg para extrair frames + Whisper para √°udio
 * ‚úÖ CORRIGIDO: Extrai frames JPEG para Vision, extrai MP3 para Whisper
 * @param params - Par√¢metros incluindo URL, thumbnail e buffer de √°udio
 * @returns Copy contextualizada baseada no v√≠deo
 */
export async function analyzeVideoForCopy(params: {
  videoUrl: string;
  thumbnailUrl: string;
  audioBuffer?: Buffer;
  fileName: string;
  objective: string;
  targetAudience: string;
}): Promise<CreativeAnalysisResult> {
  const { videoUrl, audioBuffer, fileName, objective, targetAudience } = params;
  
  console.log(`üé¨ [analyzeVideoForCopy] Analisando v√≠deo: ${fileName}`);

  let transcription: string | null = null;
  let frameBase64Images: string[] = [];
  
  // Criar arquivo tempor√°rio do v√≠deo se tiver buffer
  const tempDir = os.tmpdir();
  const videoPath = path.join(tempDir, `analyze-video-${Date.now()}.mp4`);
  
  try {
    // 1. Se tiver buffer, salvar e extrair frames + √°udio
    if (audioBuffer && audioBuffer.length > 0) {
      await fs.writeFile(videoPath, audioBuffer);
      console.log(`   üìÅ V√≠deo salvo para an√°lise: ${videoPath}`);
      
      // 1a. Extrair √°udio e transcrever
      const audioPath = await extractAudioFromVideo(videoPath);
      if (audioPath) {
        transcription = await transcribeAudioWithWhisper(audioPath);
        await fs.unlink(audioPath).catch(() => {});
        console.log(`   ‚úÖ Transcri√ß√£o: ${transcription ? 'OK' : 'Falhou'}`);
      }
      
      // 1b. Extrair frames para an√°lise visual
      const framePaths = await extractFramesFromVideo(videoPath, 0.5, 3); // 3 frames
      
      if (framePaths.length > 0) {
        // Converter frames para base64
        for (const framePath of framePaths) {
          const frameBuffer = await fs.readFile(framePath);
          frameBase64Images.push(`data:image/jpeg;base64,${frameBuffer.toString('base64')}`);
          await fs.unlink(framePath).catch(() => {}); // Limpar
        }
        console.log(`   üì∏ ${frameBase64Images.length} frames extra√≠dos para Vision`);
      }
      
      // Limpar v√≠deo tempor√°rio
      await fs.unlink(videoPath).catch(() => {});
    }
  } catch (extractError) {
    console.error('   ‚ö†Ô∏è Erro na extra√ß√£o (continuando sem):', extractError);
    await fs.unlink(videoPath).catch(() => {});
  }

  // 2. Preparar prompt para GPT Vision
  const systemPrompt = `Voc√™ √© um copywriter especialista em an√∫ncios de v√≠deo para Facebook/Instagram.
Sua miss√£o √© criar copies ALTAMENTE CONTEXTUALIZADAS baseadas no conte√∫do do v√≠deo.

${transcription ? `
TRANSCRI√á√ÉO DO √ÅUDIO DO V√çDEO:
"${transcription}"

Use trechos ou refer√™ncias ao que √© dito no v√≠deo para criar copies mais aut√™nticas e envolventes.
` : 'N√£o foi poss√≠vel transcrever o √°udio. Use apenas a an√°lise visual dos frames.'}`;

  const userPrompt = `ANALISE ${frameBase64Images.length > 0 ? 'OS FRAMES DESTE V√çDEO' : 'ESTE V√çDEO'}${transcription ? ' e considere a transcri√ß√£o do √°udio acima' : ''}.

CONTEXTO DA CAMPANHA:
- Objetivo: ${objective}
- P√∫blico-alvo: ${targetAudience}

TAREFA:
1. Descreva o que voc√™ v√™ nos frames/thumbnail
2. ${transcription ? 'Conecte o visual com o que √© dito no √°udio' : 'Crie uma narrativa baseada no visual'}
3. Gere 3 Primary Texts (80-150 chars) que ${transcription ? 'referenciem o √°udio' : 'conectem com o visual'}
4. Gere 3 Headlines (20-40 chars) impactantes

REGRAS ESPECIAIS PARA V√çDEO:
- ${transcription ? 'Use cita√ß√µes ou refer√™ncias ao √°udio: "Como eu disse no v√≠deo..."' : 'Foque no visual'}
- Crie curiosidade para assistir
- Conecte o gancho visual ao benef√≠cio

FORMATO (JSON):
{
  "imageDescription": "descri√ß√£o do que aparece no v√≠deo",
  "audioContext": "${transcription ? 'resumo do √°udio' : 'n√£o dispon√≠vel'}",
  "primaryTexts": ["texto1...", "texto2...", "texto3..."],
  "headlines": ["headline1", "headline2", "headline3"]
}

Responda APENAS com o JSON.`;

  try {
    // Construir conte√∫do com frames ou fallback para an√°lise de texto
    const contentParts: any[] = [{ type: 'text', text: userPrompt }];
    
    if (frameBase64Images.length > 0) {
      // ‚úÖ Usar frames extra√≠dos (JPEG)
      for (const base64Image of frameBase64Images) {
        contentParts.push({
          type: 'image_url',
          image_url: { url: base64Image, detail: 'low' } // low para economizar tokens
        });
      }
    } else if (params.thumbnailUrl && !params.thumbnailUrl.endsWith('.mp4')) {
      // ‚úÖ CORRIGIDO: S√≥ usar thumbnailUrl se for imagem (n√£o MP4)
      console.log('   ‚ö†Ô∏è Sem frames, usando thumbnail como imagem');
      contentParts.push({
        type: 'image_url',
        image_url: { url: params.thumbnailUrl, detail: 'low' }
      });
    } else {
      // ‚ùå Sem frames e sem thumbnail de imagem - an√°lise apenas por texto
      console.log('   ‚ö†Ô∏è Sem frames extra√≠dos e sem thumbnail. Analisando apenas por transcri√ß√£o.');
      // N√£o adiciona imagem - GPT Vision n√£o aceita MP4
    }
    
    const response = await openai.chat.completions.create({
      model: 'gpt-5.2',
      messages: [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: contentParts },
      ],
      temperature: 0.8,
      max_completion_tokens: 1000,
    });

    const content = response.choices[0]?.message?.content;
    if (!content) throw new Error('Sem resposta da OpenAI');

    const cleanContent = content.replace(/```json\n?|\n?```/g, '').trim();
    const parsed = JSON.parse(cleanContent);

    console.log('‚úÖ An√°lise de v√≠deo conclu√≠da:', {
      thumbnail: parsed.imageDescription,
      audioUsed: !!transcription,
    });

    return {
      imageDescription: parsed.imageDescription,
      audioTranscription: transcription || undefined,
      primaryTexts: parsed.primaryTexts,
      headlines: parsed.headlines,
      analysisType: transcription ? 'video' : 'video_vision_only',
    };
  } catch (error) {
    console.error('‚ùå Erro na an√°lise de v√≠deo:', error);
    
    // Fallback
    return {
      imageDescription: 'Thumbnail n√£o analisada',
      primaryTexts: [
        `üé¨ Assista ao v√≠deo e descubra como ${objective.toLowerCase()}. Milhares j√° transformaram suas vidas!`,
        `‚ñ∂Ô∏è Neste v√≠deo, explico exatamente como ${targetAudience.toLowerCase()} podem ${objective.toLowerCase()}.`,
        `üìπ O segredo que todo ${targetAudience.toLowerCase()} precisa saber est√° neste v√≠deo. Assista!`,
      ],
      headlines: [
        'Assista Agora',
        `Segredo para ${targetAudience}`,
        'N√£o Perca Este V√≠deo',
      ],
      analysisType: 'video_vision_only',
    };
  }
}

// =====================================================
// FUN√á√ÉO PRINCIPAL: Analisa criativo e gera copy
// =====================================================

/**
 * Analisa qualquer tipo de criativo (imagem ou v√≠deo) e gera copy contextualizada
 * @param params - Par√¢metros do criativo
 * @returns GeneratedCopy com textos contextualizados
 */
export async function analyzeCreativeForCopy(
  params: AnalyzeCreativeParams
): Promise<GeneratedCopy> {
  const { mediaUrl, mediaType, objective, targetAudience, thumbnailUrl, audioBuffer } = params;

  let result: CreativeAnalysisResult;

  if (mediaType === 'image') {
    result = await analyzeImageForCopy(mediaUrl, objective, targetAudience);
  } else {
    // V√≠deo: usar thumbnail para an√°lise visual
    const thumbUrl = thumbnailUrl || mediaUrl; // fallback para URL do v√≠deo
    
    result = await analyzeVideoForCopy({
      videoUrl: mediaUrl,
      thumbnailUrl: thumbUrl,
      audioBuffer,
      fileName: mediaUrl.split('/').pop() || 'video.mp4',
      objective,
      targetAudience,
    });
  }

  return {
    imageUrl: mediaUrl,
    primaryText: result.primaryTexts,
    headlines: result.headlines,
    metadata: {
      analysisType: result.analysisType,
      imageDescription: result.imageDescription,
      audioTranscription: result.audioTranscription,
    },
  };
}

// =====================================================
// HELPER: Gerar thumbnail de v√≠deo
// =====================================================

/**
 * Extrai frame do v√≠deo ou usa thumbnail da Meta
 * Para simplificar, usamos a URL do v√≠deo no Supabase como refer√™ncia
 * A Meta gera thumbnails automaticamente ap√≥s upload
 */
export async function getVideoThumbnailUrl(
  videoId: string,
  accessToken: string
): Promise<string | null> {
  try {
    const url = `https://graph.facebook.com/v21.0/${videoId}?fields=thumbnails&access_token=${accessToken}`;
    const response = await fetch(url);
    const data = await response.json();
    
    if (data.thumbnails?.data?.[0]?.uri) {
      return data.thumbnails.data[0].uri;
    }
    
    return null;
  } catch (error) {
    console.error('‚ùå Erro ao buscar thumbnail:', error);
    return null;
  }
}

// =====================================================
// HELPER: Processar m√∫ltiplos criativos
// =====================================================

/**
 * Analisa m√∫ltiplos criativos em paralelo (com limit de concorr√™ncia)
 */
export async function analyzeMultipleCreatives(
  creatives: AnalyzeCreativeParams[],
  maxConcurrency: number = 3
): Promise<GeneratedCopy[]> {
  const results: GeneratedCopy[] = [];
  
  // Processar em batches para n√£o sobrecarregar a API
  for (let i = 0; i < creatives.length; i += maxConcurrency) {
    const batch = creatives.slice(i, i + maxConcurrency);
    const batchResults = await Promise.all(
      batch.map(creative => analyzeCreativeForCopy(creative))
    );
    results.push(...batchResults);
    
    // Pequeno delay entre batches
    if (i + maxConcurrency < creatives.length) {
      await new Promise(resolve => setTimeout(resolve, 1000));
    }
  }
  
  return results;
}

// =====================================================
// CAMADA 2: An√°lise com Prompt Profissional
// =====================================================

/**
 * Analisa imagem usando um prompt profissional pr√©-gerado (Camada 2 do sistema)
 * Este m√©todo recebe o prompt da Camada 1 e usa para gerar copy mais precisa
 * 
 * @param imageUrl - URL da imagem a analisar
 * @param professionalPrompt - Prompt estruturado gerado pela Camada 1
 * @returns Copy gerada seguindo as instru√ß√µes do prompt profissional
 */
export async function analyzeWithProfessionalPrompt(
  imageUrl: string,
  professionalPrompt: string
): Promise<{
  primary_text: string;
  headline: string;
  cta: string;
}> {
  console.log('üé® [IA Layer 2] Gerando copy com prompt profissional...');

  try {
    const response = await openai.chat.completions.create({
      model: 'gpt-5.2', // Modelo mais recente (Dezembro 2025) - Suporta Vision + JSON
      messages: [
        {
          role: 'system',
          content: 'Voc√™ √© um copywriter especialista em an√∫ncios de performance. Siga EXATAMENTE as instru√ß√µes do prompt fornecido. Responda APENAS com JSON v√°lido.',
        },
        {
          role: 'user',
          content: [
            { 
              type: 'text', 
              text: professionalPrompt 
            },
            { 
              type: 'image_url', 
              image_url: { url: imageUrl, detail: 'high' } 
            },
          ],
        },
      ],
      temperature: 0.7,
      max_completion_tokens: 1000,
      response_format: { type: 'json_object' },
    });

    const content = response.choices[0]?.message?.content;
    if (!content) throw new Error('Sem resposta da OpenAI');

    const parsed = JSON.parse(content);

    console.log('‚úÖ [IA Layer 2] Copy gerada:', {
      headline: parsed.headline?.substring(0, 50),
      cta: parsed.cta,
    });

    return {
      primary_text: parsed.primary_text || parsed.primaryText || '',
      headline: parsed.headline || '',
      cta: parsed.cta || 'Saiba Mais',
    };
  } catch (error) {
    console.error('‚ùå [IA Layer 2] Erro ao gerar copy:', error);
    
    // Fallback
    return {
      primary_text: 'üéØ M√©dico, voc√™ perde horas digitando prontu√°rios?\n\nO Gravador M√©dico transcreve suas consultas automaticamente com IA.\n\nMais de 2.000 m√©dicos j√° economizam 15h/semana.\n\nTeste gr√°tis por 7 dias.',
      headline: 'Prontu√°rio pronto em segundos',
      cta: 'Come√ßar Teste Gr√°tis',
    };
  }
}

/**
 * Analisa m√∫ltiplos criativos usando o prompt profissional (Camada 2)
 * 
 * @param imageUrls - Array de URLs das imagens
 * @param professionalPrompt - Prompt estruturado gerado pela Camada 1
 * @returns Array de GeneratedCopy para cada imagem
 */
export async function analyzeMultipleWithProfessionalPrompt(
  imageUrls: string[],
  professionalPrompt: string
): Promise<GeneratedCopy[]> {
  console.log(`üé® [IA Layer 2] Analisando ${imageUrls.length} imagens com prompt profissional...`);
  
  const results: GeneratedCopy[] = [];
  
  for (const imageUrl of imageUrls) {
    try {
      const copy = await analyzeWithProfessionalPrompt(imageUrl, professionalPrompt);
      
      results.push({
        imageUrl,
        primaryText: [copy.primary_text],
        headlines: [copy.headline],
        metadata: {
          cta: copy.cta,
          analysisType: 'professional_prompt',
        },
      });
    } catch (error) {
      console.error(`‚ùå Erro ao analisar imagem ${imageUrl}:`, error);
      
      // Fallback para esta imagem
      results.push({
        imageUrl,
        primaryText: ['üéØ M√©dico, economize 15h/semana com transcri√ß√£o autom√°tica de consultas. Teste gr√°tis!'],
        headlines: ['Prontu√°rio pronto em segundos'],
        metadata: {
          cta: 'Come√ßar Teste Gr√°tis',
          analysisType: 'fallback',
        },
      });
    }
    
    // Pequeno delay entre chamadas
    await new Promise(resolve => setTimeout(resolve, 500));
  }
  
  return results;
}
